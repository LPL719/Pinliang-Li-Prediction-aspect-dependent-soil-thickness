{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44851599-5250-4484-b033-8559f9b4ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "HHO + XGBoost for Soil Thickness Prediction\n",
    "-------------------------------------------\n",
    "- Two feature groups: SSSI & SI (each plus common features)\n",
    "- For each iteration i, SSSI and SI share the SAME train/test split via random_state=i\n",
    "- HHO optimizes [max_depth, learning_rate, n_estimators]\n",
    "- Metrics recorded: R2, RMSE, MAE (train/test)\n",
    "- Results saved to: HHO_XGB_results.xlsx\n",
    "\n",
    "Usage\n",
    "-----\n",
    "$ python hho_xgb_soil.py\n",
    "\n",
    "Notes\n",
    "-----\n",
    "This refactor keeps the original behavior and randomness identical:\n",
    "- No new regularization or early stopping added\n",
    "- Parameter bounds unchanged\n",
    "- The HHO inner randomness remains as in the original script\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Configuration\n",
    "# ==============================\n",
    "\n",
    "# NOTE: Keep your actual file name here; change if you rename the source data file.\n",
    "DATA_PATH: str = \"Train_data.xlsx\"\n",
    "OUTPUT_XLSX: str = \"HHO_XGB_results.xlsx\"\n",
    "\n",
    "COMMON_COLS: List[str] = [\"DEM\", \"MRRTF\", \"NDVI\", \"MRVBF\", \"RD\"]\n",
    "GROUPS: Dict[str, List[str]] = {\n",
    "    \"SSSI\": [\"SSSI\", \"SSP\"] + COMMON_COLS,\n",
    "    \"SI\": [\"SI\", \"P\"] + COMMON_COLS,\n",
    "}\n",
    "\n",
    "# HHO parameter bounds: [max_depth, learning_rate, n_estimators]\n",
    "LB: np.ndarray = np.array([1, 0.01, 1], dtype=float)\n",
    "UB: np.ndarray = np.array([30, 0.5, 500], dtype=float)\n",
    "\n",
    "# Experiment settings\n",
    "ITERATIONS: int = 100\n",
    "SEARCH_AGENTS: int = 15\n",
    "MAX_ITER: int = 5\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Data Structures\n",
    "# ==============================\n",
    "\n",
    "@dataclass\n",
    "class HHOResult:\n",
    "    \"\"\"Container for the best solution vector found by HHO.\"\"\"\n",
    "    best_params: np.ndarray  # [max_depth, learning_rate, n_estimators]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Core Functions\n",
    "# ==============================\n",
    "\n",
    "def boundary(position: np.ndarray, lb: np.ndarray, ub: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Clip a position vector to parameter bounds.\"\"\"\n",
    "    return np.clip(position, lb, ub)\n",
    "\n",
    "\n",
    "def fitness(solution: np.ndarray,\n",
    "            X_train: pd.DataFrame, y_train: pd.Series,\n",
    "            X_val: pd.DataFrame, y_val: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Objective for HHO: minimize (1 - test R2).\n",
    "    Keeps the original modeling choices to preserve results.\n",
    "    \"\"\"\n",
    "    max_depth = int(solution[0])\n",
    "    learning_rate = float(solution[1])\n",
    "    n_estimators = int(solution[2])\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    test_r2 = r2_score(y_val, model.predict(X_val))\n",
    "    return (1.0 - test_r2)\n",
    "\n",
    "\n",
    "def hho(search_agents: int, max_iter: int,\n",
    "        X_train: pd.DataFrame, y_train: pd.Series,\n",
    "        X_val: pd.DataFrame, y_val: pd.Series) -> HHOResult:\n",
    "    \"\"\"\n",
    "    Simplified Harris Hawks Optimizer (HHO).\n",
    "    Returns the best parameter vector found.\n",
    "    \"\"\"\n",
    "    dim = 3\n",
    "    leader_pos = np.zeros(dim, dtype=float)\n",
    "    leader_score = float(\"inf\")\n",
    "\n",
    "    # Initialize population\n",
    "    positions = np.array([\n",
    "        [random.uniform(LB[d], UB[d]) for d in range(dim)]\n",
    "        for _ in range(search_agents)\n",
    "    ], dtype=float)\n",
    "\n",
    "    # Optimization loop\n",
    "    for t in range(max_iter):\n",
    "        E1 = 2 * (1 - t / max_iter)\n",
    "\n",
    "        # Evaluate and update leader\n",
    "        for i in range(search_agents):\n",
    "            fit = fitness(positions[i], X_train, y_train, X_val, y_val)\n",
    "            if fit < leader_score:\n",
    "                leader_score = fit\n",
    "                leader_pos = positions[i].copy()\n",
    "\n",
    "        # Update positions\n",
    "        for i in range(search_agents):\n",
    "            E0 = 2 * random.random() - 1\n",
    "            E = E1 * E0\n",
    "            Q = random.random()\n",
    "            J = 2 * (1 - random.random())\n",
    "\n",
    "            if abs(E) >= 1:\n",
    "                rand_idx = random.randint(0, search_agents - 1)\n",
    "                X_rand = positions[rand_idx]\n",
    "                positions[i] = X_rand - random.random() * abs(X_rand - 2 * random.random() * positions[i])\n",
    "            else:\n",
    "                if Q < 0.5:\n",
    "                    positions[i] = leader_pos - E * abs(J * leader_pos - positions[i])\n",
    "                else:\n",
    "                    positions[i] = (leader_pos - positions[i]) - E * abs(J * leader_pos - positions[i])\n",
    "\n",
    "            positions[i] = boundary(positions[i], LB, UB)\n",
    "\n",
    "            # Re-evaluate and update leader after projection\n",
    "            fit = fitness(positions[i], X_train, y_train, X_val, y_val)\n",
    "            if fit < leader_score:\n",
    "                leader_score = fit\n",
    "                leader_pos = positions[i].copy()\n",
    "\n",
    "    return HHOResult(best_params=leader_pos)\n",
    "\n",
    "\n",
    "def train_and_evaluate(group_name: str, features: List[str], iteration: int,\n",
    "                       df_clean: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Run one iteration for a feature group:\n",
    "    - Split with random_state=iteration to align splits across groups\n",
    "    - HHO -> best params\n",
    "    - Fit final XGB and compute metrics\n",
    "    \"\"\"\n",
    "    X = df_clean[features]\n",
    "    y = df_clean[\"thickness\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=0.7, random_state=iteration\n",
    "    )\n",
    "\n",
    "    # Search with HHO\n",
    "    hho_res = hho(\n",
    "        search_agents=SEARCH_AGENTS,\n",
    "        max_iter=MAX_ITER,\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        X_val=X_test, y_val=y_test\n",
    "    )\n",
    "\n",
    "    # Extract params\n",
    "    max_depth = int(hho_res.best_params[0])\n",
    "    learning_rate = float(hho_res.best_params[1])\n",
    "    n_estimators = int(hho_res.best_params[2])\n",
    "\n",
    "    # Final model\n",
    "    model = XGBRegressor(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Metrics\n",
    "    yhat_tr = model.predict(X_train)\n",
    "    yhat_te = model.predict(X_test)\n",
    "\n",
    "    result = {\n",
    "        \"Group\": group_name,\n",
    "        \"Iteration\": iteration + 1,\n",
    "        \"Train_R2\": r2_score(y_train, yhat_tr),\n",
    "        \"Test_R2\": r2_score(y_test, yhat_te),\n",
    "        \"Train_RMSE\": float(np.sqrt(mean_squared_error(y_train, yhat_tr))),\n",
    "        \"Test_RMSE\": float(np.sqrt(mean_squared_error(y_test, yhat_te))),\n",
    "        \"Train_MAE\": float(mean_absolute_error(y_train, yhat_tr)),\n",
    "        \"Test_MAE\": float(mean_absolute_error(y_test, yhat_te)),\n",
    "        \"max_depth\": max_depth,\n",
    "        \"learning_rate\": round(learning_rate, 4),\n",
    "        \"n_estimators\": n_estimators\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def summarize_results(df_results: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute group-wise mean metrics.\"\"\"\n",
    "    cols = [\"Train_R2\", \"Test_R2\", \"Test_RMSE\", \"Test_MAE\"]\n",
    "    return df_results.groupby(\"Group\")[cols].mean().reset_index()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Entry Point\n",
    "# ==============================\n",
    "\n",
    "def main() -> None:\n",
    "    # 1) Load & clean\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    # 2) Run experiments\n",
    "    rows: List[Dict[str, float]] = []\n",
    "    for group_name, feats in GROUPS.items():\n",
    "        with tqdm(total=ITERATIONS, desc=f\"HHO + XGB for {group_name}\") as pbar:\n",
    "            for i in range(ITERATIONS):\n",
    "                rows.append(\n",
    "                    train_and_evaluate(group_name, feats, i, df_clean)\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "    # 3) Collect & summarize\n",
    "    results_df = pd.DataFrame(rows)\n",
    "    grouped_mean = summarize_results(results_df)\n",
    "\n",
    "    # 4) Output\n",
    "    print(\"\\nðŸ“Š Group-wise mean results:\")\n",
    "    print(grouped_mean)\n",
    "\n",
    "    results_df.to_excel(OUTPUT_XLSX, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43043c2-66fb-4a7e-8c80-681845fe1240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
